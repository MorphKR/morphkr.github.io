(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[974],{641:e=>{e.exports={heroSection:"HeroSection_heroSection__QmdYW",content:"HeroSection_content__X7acD",title:"HeroSection_title__lVNOw",mainTitle:"HeroSection_mainTitle__956xq",subTitle:"HeroSection_subTitle__jTXIj",logo:"HeroSection_logo__a3U3E",bg:"HeroSection_bg__Owt_G",canvasMask:"HeroSection_canvasMask__DCcRb"}},1143:e=>{e.exports={contents:"MobileWorkContents_contents__hwthx",mainTitleDescription:"MobileWorkContents_mainTitleDescription__o58vU",portfolioList:"MobileWorkContents_portfolioList__bOK7M"}},1562:(e,n,t)=>{Promise.resolve().then(t.bind(t,1833)),Promise.resolve().then(t.bind(t,9672)),Promise.resolve().then(t.t.bind(t,8334,23))},1833:(e,n,t)=>{"use strict";t.d(n,{default:()=>L});var o=t(5155),a=t(641),i=t.n(a),r=t(2946),s=t.n(r),l=t(2115);let c=()=>{let e=(0,l.useRef)(null);return(0,l.useEffect)(()=>{let n=e.current;if(n){n.innerHTML="";for(let e=0;e<30;e++){let t=document.createElement("div"),o=e%2==0?-1:1,a=100*Math.random(),i=100*Math.random(),r=(5*Math.random()+5)*o,l=a+8*Math.random()+5,c=i+8*Math.random()+5,d=r+(20*Math.random()+2)*o,v=2*Math.random()+1,p=20*Math.random()+5,m=-21*Math.random(),f=.5*Math.random()+.2;t.style.setProperty("--pos-x-s","".concat(a,"vw")),t.style.setProperty("--pos-y-s","".concat(i,"vh")),t.style.setProperty("--angle-s","".concat(r,"deg")),t.style.setProperty("--pos-x-e","".concat(l,"vw")),t.style.setProperty("--pos-y-e","".concat(c,"vh")),t.style.setProperty("--angle-e","".concat(d,"deg")),t.style.setProperty("--scale","".concat(v)),t.style.setProperty("--duration","".concat(p,"s")),t.style.setProperty("--delay","".concat(m,"s")),t.style.setProperty("--opacity","".concat(f)),t.className=s().prismPiece,n.appendChild(t)}}},[]),(0,o.jsx)("div",{ref:e,className:s().prism})};var d=t(7907),v=t.n(d);let p=e=>{let{children:n}=e,t=(0,l.useRef)(null),[a,i]=(0,l.useState)(!1),r=(0,l.useRef)({x:0,y:0});return(0,l.useEffect)(()=>{let e,n=0,o=0,i=1/8,s=()=>window.innerWidth<=480?1.3:window.innerWidth<=768?1.2:window.innerWidth<=1024?1:window.innerWidth<=1440?.9:1,l=()=>{a||(n=.4*r.current.x,o=.4*r.current.y),r.current.x+=(n-r.current.x)*i,r.current.y+=(o-r.current.y)*i,t.current&&(t.current.style.transform="translate(-50%, -50%) perspective(600px) rotateY(".concat(r.current.x,"deg) rotateX(").concat(-r.current.y,"deg)")),e=window.requestAnimationFrame(l)},c=(e,t)=>{if(!a)return;let i=s(),r=Math.max(-100,Math.min(100,window.innerWidth/2-e)),l=Math.max(-100,Math.min(100,window.innerHeight/2-t));n=12*r*i/100,o=10*l*i/100},d=e=>{c(e.clientX,e.clientY)},v=e=>{if(e.touches.length>0&&a){let n=e.touches[0];c(n.clientX,n.clientY),e.preventDefault()}};return window.addEventListener("mousemove",d),window.addEventListener("touchmove",v,{passive:!1}),window.addEventListener("click",d),l(),()=>{window.removeEventListener("mousemove",d),window.removeEventListener("touchmove",v),window.removeEventListener("click",d),window.cancelAnimationFrame(e)}},[a]),(0,o.jsxs)("div",{ref:t,className:v().wrapper,"data-hovered":a,onMouseEnter:()=>{i(!0)},onMouseLeave:()=>{i(!1)},onTouchStart:e=>{i(!0)},onTouchEnd:e=>{i(!1)},children:[(0,o.jsx)("div",{className:v().me}),(0,o.jsx)("div",{className:v().text})]})};var m=t(5623),f=t(4521),u=t(337);class x extends u.BKk{constructor(e){super({defines:{BLUR_SLOD:4,IS_THREEJS_EXPORT:!0,NUM_SAMPLES:6,g_uid30_IS_VECTOR:1,g_uid30_LINEAR:1,g_uid30_MAX_COLORS:2},uniforms:{outgoingLight:{value:e.outgoingLight||new u.Q1f(203,203,203)},alpha:{value:e.alpha||50},thickness:{value:e.thickness||3},ior:{value:e.ior||1.19},roughness:{value:e.roughness||5},transmissionSamplerSize:{value:e.transmissionSamplerSize},transmissionSamplerMap:{value:e.transmissionSamplerMap},transmissionDepthMap:{value:null},aspectRatio:{value:e.aspectRatio},mask:{value:1},opacity:{value:.7},fogDensity:{value:25e-5},fogNear:{value:1},fogFar:{value:2e3},fogColor:{value:new u.Q1f(1,1,1)},hasNormalMap:{value:!!e.normalMap},normalMap:{value:e.normalMap},normalScale:{value:e.normalScale||new u.I9Y(1,1)}},vertexShader:"\n#ifdef TEXTURE_LOD_EXT\n	#define texCube(a, b) textureCube(a, b)\n	#define texCubeBias(a, b, c) textureCubeLodEXT(a, b, c)\n	#define tex2D(a, b) texture2D(a, b)\n	#define tex2DBias(a, b, c) texture2DLodEXT(a, b, c)\n#else\n	#define texCube(a, b) textureCube(a, b)\n	#define texCubeBias(a, b, c) textureCube(a, b, c)\n	#define tex2D(a, b) texture2D(a, b)\n	#define tex2DBias(a, b, c) texture2D(a, b, c)\n#endif\n\n			// NOTE: Include Spline's blending modes. This could be part of BlendNode\n			#define SPE_BLENDING_NORMAL 0\n			#define SPE_BLENDING_MULTIPLY 1\n			#define SPE_BLENDING_SCREEN 2\n			#define SPE_BLENDING_OVERLAY 3\n\n			vec3 spe_normalBlend( vec3 a, vec3 b, float alpha ) {\n				return mix( a, b, alpha );\n			}\n\n			vec3 spe_multiplyBlend( vec3 a, vec3 b, float alpha ) {\n				return mix( a, a * b, alpha );\n			}\n\n			vec3 spe_screenBlend( vec3 a, vec3 b, float alpha ) {\n				vec3 tmp = 1.0 - ( 1.0 - a ) * ( 1.0 - b );\n				return mix( a, tmp, alpha );\n			}\n\n			vec3 spe_overlayBlend( vec3 a, vec3 b, float alpha ) {\n				vec3 tmp = mix( 1. - 2. * (1. - a) * (1. - b), 2. * a * b, step( a, vec3(.5) ) );\n				return clamp( mix( a, tmp, alpha ), 0.0, 1.0 );\n			}\n\n			vec3 spe_blend( vec3 a, vec3 b, float alpha, int mode ) {\n				if ( mode == SPE_BLENDING_NORMAL ) return spe_normalBlend( a, b, alpha );\n				else if ( mode == SPE_BLENDING_MULTIPLY ) return spe_multiplyBlend( a, b, alpha );\n				else if ( mode == SPE_BLENDING_SCREEN ) return spe_screenBlend( a, b, alpha );\n				else if ( mode == SPE_BLENDING_OVERLAY ) return spe_overlayBlend( a, b, alpha );\n				return vec3( 1.0 );\n			}\n\n#include <packing>\n#include <common>\nfloat neighbor_offset = 0.0001;\n\nuniform int frameIndex;\nuniform vec2 resolution;\nuniform mat4 previousModelViewMatrix;\nuniform mat4 previousProjectionMatrix;\n\nvarying vec4 vCurrentPosition;\nvarying vec4 vPreviousPosition;\n\nvarying vec3 vViewPosition;\nvarying vec3 vWPosition;\n#include <fog_pars_vertex>\n#include <skinning_pars_vertex>\n#include <normal_pars_vertex>\n#include <morphtarget_pars_vertex>\nvarying vec2 vUv;\nvarying vec3 vPosition;\nvarying vec3 vObjectNormal;\nvarying vec3 vWNormal;\nvarying vec3 vWorldViewDir;\n\nvoid main() {\n\n\n#include <beginnormal_vertex>\n#include <morphnormal_vertex>\n\n				#include <skinbase_vertex>\n				#include <skinnormal_vertex>\n				#if !defined( USE_LAYER_DISPLACE )\n					#include <defaultnormal_vertex>\n				#endif\n\n				vec3 displaced_position = position;\n				vec3 displaced_normal = normal;\n\n				#if defined( USE_LAYER_DISPLACE )\n					vec3 transformed;\n					vec3 transformedNormal;\n				#endif\n\n#include <normal_vertex>\n\n				#if !defined( USE_LAYER_DISPLACE )\n					#include <begin_vertex>\n				#endif /* !USE_LAYER_DISPLACE */\n\ntransformed = displaced_position;\n#include <morphtarget_vertex>\n#include <skinning_vertex>\ntransformedNormal = normalMatrix * displaced_normal;\n#ifndef FLAT_SHADED\n	vNormal = transformedNormal;\n#endif\n#include <project_vertex>\n#include <fog_vertex>\n#include <clipping_planes_vertex>\n	vViewPosition = - mvPosition.xyz;\n#include <worldpos_vertex>\nvWPosition = ( modelMatrix * vec4( transformed, 1.0 ) ).xyz;\nvUv = uv;\nvPosition = transformed;\n\n				#ifndef SHAPEBLEND\n					vObjectNormal = normal;\n				#else\n					vObjectNormal = objectNormal;\n				#endif\n\nvWNormal = inverseTransformDirection( transformedNormal, viewMatrix ).xyz;\nvWorldViewDir = isPerspectiveMatrix( projectionMatrix ) ?  ( (modelMatrix * vec4(position, 1.0)).xyz - cameraPosition ) : vec3( -viewMatrix[0][2], -viewMatrix[1][2], -viewMatrix[2][2] );\n\n}\n",fragmentShader:'\n#ifdef TEXTURE_LOD_EXT\n	#define texCube(a, b) textureCube(a, b)\n	#define texCubeBias(a, b, c) textureCubeLodEXT(a, b, c)\n	#define tex2D(a, b) texture2D(a, b)\n	#define tex2DBias(a, b, c) texture2DLodEXT(a, b, c)\n#else\n	#define texCube(a, b) textureCube(a, b)\n	#define texCubeBias(a, b, c) textureCube(a, b, c)\n	#define tex2D(a, b) texture2D(a, b)\n	#define tex2DBias(a, b, c) texture2D(a, b, c)\n#endif\n\n// NOTE: Include Spline\'s blending modes. This could be part of BlendNode\n#define SPE_BLENDING_NORMAL 0\n#define SPE_BLENDING_MULTIPLY 1\n#define SPE_BLENDING_SCREEN 2\n#define SPE_BLENDING_OVERLAY 3\n\nvec3 spe_normalBlend( vec3 a, vec3 b, float alpha ) {\n	return mix( a, b, alpha );\n}\n\nvec3 spe_multiplyBlend( vec3 a, vec3 b, float alpha ) {\n	return mix( a, a * b, alpha );\n}\n\nvec3 spe_screenBlend( vec3 a, vec3 b, float alpha ) {\n	vec3 tmp = 1.0 - ( 1.0 - a ) * ( 1.0 - b );\n	return mix( a, tmp, alpha );\n}\n\nvec3 spe_overlayBlend( vec3 a, vec3 b, float alpha ) {\n	vec3 tmp = mix( 1. - 2. * (1. - a) * (1. - b), 2. * a * b, step( a, vec3(.5) ) );\n	return clamp( mix( a, tmp, alpha ), 0.0, 1.0 );\n}\n\nvec3 spe_blend( vec3 a, vec3 b, float alpha, int mode ) {\n	if ( mode == SPE_BLENDING_NORMAL ) return spe_normalBlend( a, b, alpha );\n	else if ( mode == SPE_BLENDING_MULTIPLY ) return spe_multiplyBlend( a, b, alpha );\n	else if ( mode == SPE_BLENDING_SCREEN ) return spe_screenBlend( a, b, alpha );\n	else if ( mode == SPE_BLENDING_OVERLAY ) return spe_overlayBlend( a, b, alpha );\n	return vec3( 1.0 );\n}\n			\n#include <packing>\n#include <common>\nfloat accumAlpha = 0.0;\nvoid accumulateAlpha(float alpha) {\n					accumAlpha += (1.0 - accumAlpha) * alpha;\n				}\n\nlayout(location = 1) out vec4 gVelocity;\n\nuniform int frameIndex;\nuniform vec2 resolution;\n\nvarying vec4 vCurrentPosition;\nvarying vec4 vPreviousPosition;\n\nconst vec2 haltonSequence[16] = vec2[16](\nvec2( 0.000000,-0.333334),\nvec2(-0.500000, 0.333334),\nvec2( 0.500000,-0.777778),\nvec2(-0.750000,-0.111112),\nvec2( 0.250000, 0.555556),\nvec2(-0.250000,-0.555556),\nvec2( 0.750000, 0.111112),\nvec2(-0.875000, 0.777778),\nvec2(0.125000, -0.925926),\nvec2(-0.375000, -0.259260),\nvec2(0.625000, 0.407408),\nvec2(-0.625000, -0.703704),\nvec2(0.375000, -0.037038),\nvec2(-0.125000, 0.629630),\nvec2(0.875000, -0.481482),\nvec2(-0.937500, 0.185186));\n\nvec2 vogelDiskSample(int sampleIndex, int sampleCount, float angle) {\n  const float goldenAngle = 2.399963f; // radians\n  float r = sqrt(float(sampleIndex) + 0.5f) / sqrt(float(sampleCount));\n  float theta = float(sampleIndex) * goldenAngle + angle;\n  float sine = sin(theta);\n  float cosine = cos(theta);\n  return vec2(cosine, sine) * r;\n}\n\n// Derived from the interleaved gradient function from Jimenez 2014 http:goo.gl/eomGso\nfloat getNoiseInterleavedGradient(vec2 screenPos) {\n    vec3 magic = vec3(0.06711056f, 0.00583715f, 52.9829189f);\n    return fract(magic.z * fract(dot(screenPos, magic.xy)));\n}\n\n\nvarying vec3 vWPosition;\n#include <fog_pars_fragment>\n#include <dithering_pars_fragment>\nvarying vec3 vViewPosition;\n#include <normal_pars_fragment>\nvarying vec2 vUv;\nvarying vec3 vPosition;\nvarying vec3 vObjectNormal;\nuniform mat4 modelMatrix;\nuniform mat4 projectionMatrix;\nvarying vec3 vWNormal;\nvarying vec3 vWorldViewDir;\n\n\nuniform vec3 outgoingLight;  // outgoingLight: 기본 색상\nuniform float alpha;  // alpha: 투명도\nuniform float thickness;  // thickness: 두께\nuniform float ior;  // ior: 굴절률\nuniform float roughness;  // roughness: 거칠기\nuniform vec2 transmissionSamplerSize;  // transmissionSamplerSize: 전송 샘플러 크기\nuniform sampler2D transmissionSamplerMap;  // transmissionSamplerMap: 전송 샘플러 맵\nuniform sampler2D transmissionDepthMap;  // transmissionDepthMap: 전송 깊이 맵\nuniform vec2 aspectRatio;  // aspectRatio: 종횡비\nuniform float mask;  // mask: 마스크\nuniform float opacity;\nuniform bool hasNormalMap;\nuniform sampler2D normalMap;  // normalMap: 노말 맵\nuniform vec2 normalScale;  // normalScale: 노말 스케일\n\nconst float F3 = 0.3333333;\nconst float G3 = 0.1666667;\nconst int NUM_OCTAVES = 5;\n\n\nfloat w0( float a ) {\n	return ( 1.0 / 6.0 ) * ( a * ( a * ( - a + 3.0 ) - 3.0 ) + 1.0 );\n}\n    \nfloat w1( float a ) {\n	return ( 1.0 / 6.0 ) * ( a *  a * ( 3.0 * a - 6.0 ) + 4.0 );\n}\n\nfloat w2( float a ){\n	return ( 1.0 / 6.0 ) * ( a * ( a * ( - 3.0 * a + 3.0 ) + 3.0 ) + 1.0 );\n}\n\nfloat w3( float a ) {\n	return ( 1.0 / 6.0 ) * ( a * a * a );\n}\n\n// g0 and g1 are the two amplitude functions\nfloat g0( float a ) {\n	return w0( a ) + w1( a );\n}\n\nfloat g1( float a ) {\n	return w2( a ) + w3( a );\n}\n\n// h0 and h1 are the two offset functions\nfloat h0( float a ) {\n	return - 1.0 + w1( a ) / ( w0( a ) + w1( a ) );\n}\n\nfloat h1( float a ) {\n	return 1.0 + w3( a ) / ( w2( a ) + w3( a ) );\n}\n\nvec4 bicubic( sampler2D tex, vec2 vUv, vec4 texelSize, float lod ) {\n	vUv = vUv * texelSize.zw + 0.5;\n\n	vec2 iuv = floor( vUv );\n	vec2 fuv = fract( vUv );\n\n	float g0x = g0( fuv.x );\n	float g1x = g1( fuv.x );\n	float h0x = h0( fuv.x );\n	float h1x = h1( fuv.x );\n	float h0y = h0( fuv.y );\n	float h1y = h1( fuv.y );\n\n	vec2 p0 = ( vec2( iuv.x + h0x, iuv.y + h0y ) - 0.5 ) * texelSize.xy;\n	vec2 p1 = ( vec2( iuv.x + h1x, iuv.y + h0y ) - 0.5 ) * texelSize.xy;\n	vec2 p2 = ( vec2( iuv.x + h0x, iuv.y + h1y ) - 0.5 ) * texelSize.xy;\n	vec2 p3 = ( vec2( iuv.x + h1x, iuv.y + h1y ) - 0.5 ) * texelSize.xy;\n\n	return g0( fuv.y ) * ( g0x * textureLod( tex, p0, lod ) + g1x * textureLod( tex, p1, lod ) ) + \n			g1( fuv.y ) * ( g0x * textureLod( tex, p2, lod ) + g1x * textureLod( tex, p3, lod ) );\n}\n\nvec4 textureBicubic( sampler2D sampler, vec2 vUv, float lod ) {\n	vec2 fLodSize = vec2( textureSize( sampler, int( lod ) ) );\n	vec2 cLodSize = vec2( textureSize( sampler, int( lod + 1.0 ) ) );\n	vec2 fLodSizeInv = 1.0 / fLodSize;\n	vec2 cLodSizeInv = 1.0 / cLodSize;\n	vec4 fSample = bicubic( sampler, vUv, vec4( fLodSizeInv, fLodSize ), floor( lod ) );\n	vec4 cSample = bicubic( sampler, vUv, vec4( cLodSizeInv, cLodSize ), ceil( lod ) );\n	return mix( fSample, cSample, fract( lod ) );\n}\n\nfloat applyIorToRoughness( float roughness, float ior ) {\n	// Scale roughness with IOR so that an IOR of 1.0 results in no microfacet refraction and\n	// an IOR of 1.5 results in the default amount of microfacet refraction.\n	return roughness * clamp( ior * 2.0 - 2.0, 0.0, 1.0 );\n}\n\nvec3 blur(sampler2D sp, vec2 U, vec2 scale, float lod, sampler2D dm, vec2 unrefractedU, vec2 aspectRatio) {\n	// Slightly modified version of this:\n	// https://www.shadertoy.com/view/ltScRG\n\n	// Special case for blur == 0.0\n	if (lod == 0.0) {\n		#ifdef TEXTURE_LOD_EXT\n		return texture2DLodEXT( sp, U, 0.0).rgb;\n		#else\n		return textureLod( sp, U, 0.0).rgb;\n		#endif\n	}\n	\n	vec2 texelSize = vec2(1.0) / resolution;\n	vec2 halton = haltonSequence[frameIndex];\n	float temporalOffset = getNoiseInterleavedGradient(gl_FragCoord.xy + halton);\n	float temporalAngle  = temporalOffset * PI2;\n	vec3 res = vec3(0.0);\n	vec2 vUv = vec2(0.0);\n	vec2 offset = vec2(0.0);\n	vec2 vogelSample = vec2(0.0);\n	for (int i = 0; i < NUM_SAMPLES; i++) {\n		vogelSample =  vogelDiskSample(i, NUM_SAMPLES, temporalAngle) * texelSize;\n		offset = vogelSample * scale * (lod * 10.0); // TODO: used to be hardcoded to 20\n		vUv = U + offset;\n		float opaqueDepth = unpackRGBAToDepth(textureLod(dm, vUv, lod));\n		if (opaqueDepth != 0.0 && opaqueDepth < gl_FragCoord.z) {\n			vUv = unrefractedU;\n			lod = lod > 4.0 ? lod : lod / 2.0;\n		}\n		res += textureLod(sp, vUv, lod).rgb;\n	}\n	return res / float(NUM_SAMPLES);\n}\n\nvec3 getVolumeTransmissionRay( vec3 n, vec3 v, float thickness, float ior, mat4 modelMatrix ) {\n	// Direction of refracted light.\n	vec3 refractionVector = refract( -v,  n, 1.0 / ior );\n	\n	// Compute rotation-independant scaling of the model matrix.\n	vec3 modelScale;\n	modelScale.x = length( vec3( modelMatrix[ 0 ].xyz ) );\n	modelScale.y = length( vec3( modelMatrix[ 1 ].xyz ) );\n	modelScale.z = length( vec3( modelMatrix[ 2 ].xyz ) );\n\n	// The thickness is specified in local space\n	return normalize( refractionVector ) * thickness * modelScale;\n}\n\nvec3 random3(vec3 c) {\n	float j = 4096.0*sin(dot(c,vec3(17.0, 59.4, 15.0)));\n	vec3 r;\n	r.z = fract(512.0*j);\n	j *= .125;\n	r.x = fract(512.0*j);\n	j *= .125;\n	r.y = fract(512.0*j);\n	return r-0.5;\n}\n\nvec4 permute(vec4 x){return mod(((x*34.0)+1.0)*x, 289.0);}\nvec4 taylorInvSqrt(vec4 r){return 1.79284291400159 - 0.85373472095314 * r;}\nvec4 mod289(vec4 x){return x - floor(x * (1.0 / 289.0)) * 289.0;}\nvec3 fade(vec3 t) {return t*t*t*(t*(t*6.0-15.0)+10.0);}\nfloat hashwithoutsine13(vec3 p3)\n{\n	p3  = fract(p3 * .1031);\n	p3 += dot(p3, p3.yzx + 33.33);\n	return fract((p3.x + p3.y) * p3.z);\n}\nvec3 hashwithoutsine33(vec3 p3)\n{\n	p3 = fract(p3 * vec3(.1031, .1030, .0973));\n	p3 += dot(p3, p3.yxz+33.33);\n	return fract((p3.xxy + p3.yxx)*p3.zyx);\n}\nfloat metric(in vec3 p)\n{\n	// L2 \n	return length(p);\n\n	// Chebyshev \n	// vec3 a = abs(p);\n	// return max(a.x, max(a.y, a.z));\n}\nfloat smin( float a, float b, float k )\n{\n	float h = smoothstep(0.0, 1.0, 0.5 + 0.5 * (b - a) / k);\n	float correction = k * h * (1.0 - h);\n	return mix(b, a, h) - correction;\n}\nfloat smax( float a, float b, float k )\n{\n	float h = smoothstep(1.0, 0.0, 0.5 + 0.5 * (a - b) / k);\n	float correction = k * h * (1.0 - h);\n	return mix(a, b, h) + correction;\n}\nfloat remap(float value, float input_min, float input_max, float output_min, float output_max) {\n	// Compute width of each interval\n	float input_width = input_max - input_min;\n	float output_width = output_max - output_min;\n\n	// Convert input range into a 0-1 range \n	float scaled = (value - input_min) / input_width;\n\n	// Convert the 0-1 range into a value in output range\n	return output_min + (scaled * output_width);\n}\nvec3 uvTexture(vec3 normal, sampler2D tex, vec2 textureSize, float crop, mat3 mat, vec2 size, float blending, bool isMask, float mask, float alpha, int mode, out float calpha, out vec2 writeUv) {\n	vec2 uvs = ( mat * vec3( vUv * 2. - 1., 1. ) / 2. + 0.5 ).xy;\n	writeUv = uvs;\n\n	vec4 tmp = texture2D( tex, uvs );\n\n	vec3 col = tmp.rgb;\n\n	float lalpha = alpha * tmp.a;\n	if ( crop > 0.5 ) {\n		if ( uvs.x < 0.0 || uvs.x > 1.0 || uvs.y < 0.0 || uvs.y > 1.0 )  {\n			lalpha = 0.0;\n		}\n	}\n	\n	lalpha *= mask;\n\n	calpha =  lalpha / clamp( lalpha + accumAlpha, 0.00001, 1.0 );\n	accumAlpha += (1.0 - accumAlpha) * lalpha * (1.0 - float(isMask));\n\n	return col;\n}\nfloat vectorLinearWorldSpaceDepth(vec3 direction, vec3 origin, float near, float far) {\n	vec3 n = normalize(direction);\n	float dist = (n.x*(vWPosition.x - origin.x) + n.y*(vWPosition.y - origin.y) + n.z*(vWPosition.z - origin.z));\n	return ( dist - near ) / ( far - near );\n}\nfloat vectorLinearObjectSpaceDepth(vec3 direction, vec3 origin, float near, float far) {\n	vec3 n = normalize(direction);\n	float dist = (n.x*(vPosition.x - origin.x) + n.y*(vPosition.y - origin.y) + n.z*(vPosition.z - origin.z));\n	return ( dist - near ) / ( far - near );\n}\nfloat vectorSphericalObjectSpaceDepth(vec3 origin, float near, float far) {\n	float dist = length(vPosition - origin);\n	return ( dist - near ) / ( far - near );\n}\nfloat vectorSphericalWorldSpaceDepth(vec3 origin, float near, float far) {\n	float dist = length(vWPosition - origin);\n	return ( dist - near ) / ( far - near );\n}\nfloat simplexFast(vec3 p) {\n		vec3 s = floor(p + dot(p, vec3(F3)));\n		mediump vec3 x = p - s + dot(s, vec3(G3));\n		mediump vec3 hs = s;\n		\n		mediump vec3 e = step(vec3(0.0), x - x.yzx);\n		mediump vec3 i1 = e*(1.0 - e.zxy);\n		mediump vec3 i2 = 1.0 - e.zxy*(1.0 - e);\n		\n		mediump vec3 x1 = x - i1 + G3;\n		mediump vec3 x2 = x - i2 + 2.0*G3;\n		mediump vec3 x3 = x - 1.0 + 3.0*G3;\n		\n		mediump vec4 w, d;\n		\n		w.x = dot(x, x);\n		w.y = dot(x1, x1);\n		w.z = dot(x2, x2);\n		w.w = dot(x3, x3);\n		\n		w = max(0.6 - w, 0.0);\n		\n		d.x = dot(random3(hs), x);\n		d.y = dot(random3(hs + i1), x1);\n		d.z = dot(random3(hs + i2), x2);\n		d.w = dot(random3(hs + 1.0), x3);\n		\n		w *= w;\n		w *= w;\n		d *= w;\n		\n		return dot(d, vec4(52.0));\n}\nvec4 perm(vec4 x){return mod289(((x * 34.0) + 1.0) * x);}\nfloat simplexFractal(vec3 m) {\n	mat3 rot1 = mat3(-0.37, 0.36, 0.85,-0.14,-0.93, 0.34,0.92, 0.01,0.4);\n	mat3 rot2 = mat3(-0.55,-0.39, 0.74, 0.33,-0.91,-0.24,0.77, 0.12,0.63);\n	mat3 rot3 = mat3(-0.71, 0.52,-0.47,-0.08,-0.72,-0.68,-0.7,-0.45,0.56);\n	return 0.5333333 * simplexFast(m * rot1)\n			+ 0.2666667 * simplexFast(2.0 * m * rot2)\n			+ 0.1333333 * simplexFast(4.0 * m * rot3)\n			+ 0.0666667 * simplexFast(8.0 * m);\n}\nfloat simplexAshima(vec3 v) {\n	const vec2  C = vec2(1.0/6.0, 1.0/3.0) ;\n	const vec4  D = vec4(0.0, 0.5, 1.0, 2.0);\n	vec3 i  = floor(v + dot(v, C.yyy) );\n	vec3 x0 =   v - i + dot(i, C.xxx) ;\n	vec3 g = step(x0.yzx, x0.xyz);\n	vec3 l = 1.0 - g;\n	vec3 i1 = min( g.xyz, l.zxy );\n	vec3 i2 = max( g.xyz, l.zxy );\n	vec3 x1 = x0 - i1 + 1.0 * C.xxx;\n	vec3 x2 = x0 - i2 + 2.0 * C.xxx;\n	vec3 x3 = x0 - 1. + 3.0 * C.xxx;\n	i = mod(i, 289.0 ); \n	vec4 p = permute( permute( permute( \n				i.z + vec4(0.0, i1.z, i2.z, 1.0 ))\n			+ i.y + vec4(0.0, i1.y, i2.y, 1.0 )) \n			+ i.x + vec4(0.0, i1.x, i2.x, 1.0 ));\n	float n_ = 1.0/7.0; // N=7\n	vec3  ns = n_ * D.wyz - D.xzx;\n	vec4 j = p - 49.0 * floor(p * ns.z *ns.z);  //  mod(p,N*N)\n	vec4 x_ = floor(j * ns.z);\n	vec4 y_ = floor(j - 7.0 * x_ );    // mod(j,N)\n	vec4 x = x_ *ns.x + ns.yyyy;\n	vec4 y = y_ *ns.x + ns.yyyy;\n	vec4 h = 1.0 - abs(x) - abs(y);\n	vec4 b0 = vec4( x.xy, y.xy );\n	vec4 b1 = vec4( x.zw, y.zw );\n	vec4 s0 = floor(b0)*2.0 + 1.0;\n	vec4 s1 = floor(b1)*2.0 + 1.0;\n	vec4 sh = -step(h, vec4(0.0));\n	vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy ;\n	vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww ;\n	vec3 p0 = vec3(a0.xy,h.x);\n	vec3 p1 = vec3(a0.zw,h.y);\n	vec3 p2 = vec3(a1.xy,h.z);\n	vec3 p3 = vec3(a1.zw,h.w);\n	vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));\n	p0 *= norm.x;\n	p1 *= norm.y;\n	p2 *= norm.z;\n	p3 *= norm.w;\n	vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);\n	m = m * m;\n	return 42.0 * dot( m*m, vec4( dot(p0,x0), dot(p1,x1), \n								dot(p2,x2), dot(p3,x3) ) );\n}\nfloat noise(vec3 p){\n	vec3 a = floor(p);\n	vec3 d = p - a;\n	d = d * d * (3.0 - 2.0 * d);\n	vec4 b = a.xxyy + vec4(0.0, 1.0, 0.0, 1.0);\n	vec4 k1 = perm(b.xyxy);\n	vec4 k2 = perm(k1.xyxy + b.zzww);\n	vec4 c = k2 + a.zzzz;\n	vec4 k3 = perm(c);\n	vec4 k4 = perm(c + 1.0);\n	vec4 o1 = fract(k3 * (1.0 / 41.0));\n	vec4 o2 = fract(k4 * (1.0 / 41.0));\n	vec4 o3 = o2 * d.z + o1 * (1.0 - d.z);\n	vec2 o4 = o3.yw * d.x + o3.xz * (1.0 - d.x);\n	return o4.y * d.y + o4.x * (1.0 - d.y);\n}\nvec3 getTransmissionSample( vec2 fragCoord, float roughness, float ior, vec2 transmissionSamplerSize, sampler2D transmissionSamplerMap, sampler2D transmissionDepthMap, vec2 unrefractedCoords, vec2 aspectRatio) {\n	// Threejs exports do not pass a depth map to this shader, so we have to fallback to the "Threejs method of blurring" - see\n	// also the code in convertTransmission.ts, which runs during export\n	#ifdef IS_THREEJS_EXPORT\n		float lod = log2(transmissionSamplerSize.x) * applyIorToRoughness(roughness / 5.0, ior);\n		return textureBicubic(transmissionSamplerMap, fragCoord.xy, lod).rgb;\n	#else\n		float framebufferLod = log2( transmissionSamplerSize.x ) * applyIorToRoughness( roughness, ior );\n		float lod = applyIorToRoughness(roughness, ior);\n		return blur(transmissionSamplerMap, fragCoord, vec2(lod), min(framebufferLod / 5.5, 8.5), transmissionDepthMap, unrefractedCoords, aspectRatio);\n	#endif\n}\nfloat fbm(vec3 x) {\n	float v = 0.0;\n	float a = 0.5;\n	vec3 shift = vec3(100);\n	for (int i = 0; i < NUM_OCTAVES; ++i) {\n		v += a * noise(x);\n		x = x * 2.0 + shift;\n		a *= 0.5;\n	}\n	return v;\n}\nfloat perlin(vec3 P){\n	vec3 Pi0 = floor(P);\n	vec3 Pi1 = Pi0 + vec3(1.0);\n	Pi0 = mod(Pi0, 289.0);\n	Pi1 = mod(Pi1, 289.0);\n	vec3 Pf0 = fract(P);\n	vec3 Pf1 = Pf0 - vec3(1.0);\n	vec4 ix = vec4(Pi0.x, Pi1.x, Pi0.x, Pi1.x);\n	vec4 iy = vec4(Pi0.yy, Pi1.yy);\n	vec4 iz0 = Pi0.zzzz;\n	vec4 iz1 = Pi1.zzzz;\n	vec4 ixy = permute(permute(ix) + iy);\n	vec4 ixy0 = permute(ixy + iz0);\n	vec4 ixy1 = permute(ixy + iz1);\n	vec4 gx0 = ixy0 / 7.0;\n	vec4 gy0 = fract(floor(gx0) / 7.0) - 0.5;\n	gx0 = fract(gx0);\n	vec4 gz0 = vec4(0.5) - abs(gx0) - abs(gy0);\n	vec4 sz0 = step(gz0, vec4(0.0));\n	gx0 -= sz0 * (step(0.0, gx0) - 0.5);\n	gy0 -= sz0 * (step(0.0, gy0) - 0.5);\n	vec4 gx1 = ixy1 / 7.0;\n	vec4 gy1 = fract(floor(gx1) / 7.0) - 0.5;\n	gx1 = fract(gx1);\n	vec4 gz1 = vec4(0.5) - abs(gx1) - abs(gy1);\n	vec4 sz1 = step(gz1, vec4(0.0));\n	gx1 -= sz1 * (step(0.0, gx1) - 0.5);\n	gy1 -= sz1 * (step(0.0, gy1) - 0.5);\n	vec3 g000 = vec3(gx0.x,gy0.x,gz0.x);\n	vec3 g100 = vec3(gx0.y,gy0.y,gz0.y);\n	vec3 g010 = vec3(gx0.z,gy0.z,gz0.z);\n	vec3 g110 = vec3(gx0.w,gy0.w,gz0.w);\n	vec3 g001 = vec3(gx1.x,gy1.x,gz1.x);\n	vec3 g101 = vec3(gx1.y,gy1.y,gz1.y);\n	vec3 g011 = vec3(gx1.z,gy1.z,gz1.z);\n	vec3 g111 = vec3(gx1.w,gy1.w,gz1.w);\n	vec4 norm0 = taylorInvSqrt(vec4(dot(g000, g000), dot(g010, g010), dot(g100, g100), dot(g110, g110)));\n	g000 *= norm0.x;\n	g010 *= norm0.y;\n	g100 *= norm0.z;\n	g110 *= norm0.w;\n	vec4 norm1 = taylorInvSqrt(vec4(dot(g001, g001), dot(g011, g011), dot(g101, g101), dot(g111, g111)));\n	g001 *= norm1.x;\n	g011 *= norm1.y;\n	g101 *= norm1.z;\n	g111 *= norm1.w;\n	float n000 = dot(g000, Pf0);\n	float n100 = dot(g100, vec3(Pf1.x, Pf0.yz));\n	float n010 = dot(g010, vec3(Pf0.x, Pf1.y, Pf0.z));\n	float n110 = dot(g110, vec3(Pf1.xy, Pf0.z));\n	float n001 = dot(g001, vec3(Pf0.xy, Pf1.z));\n	float n101 = dot(g101, vec3(Pf1.x, Pf0.y, Pf1.z));\n	float n011 = dot(g011, vec3(Pf0.x, Pf1.yz));\n	float n111 = dot(g111, Pf1);\n	vec3 fade_xyz = fade(Pf0);\n	vec4 n_z = mix(vec4(n000, n100, n010, n110), vec4(n001, n101, n011, n111), fade_xyz.z);\n	vec2 n_yz = mix(n_z.xy, n_z.zw, fade_xyz.y);\n	float n_xyz = mix(n_yz.x, n_yz.y, fade_xyz.x); \n	return 2.2 * n_xyz;\n}\nvec3 g_uid30_sdepth(float near, float far, vec3 origin, vec3 direction, vec4 colors[g_uid30_MAX_COLORS], float steps[g_uid30_MAX_COLORS], bool isMask, float mask, float alpha, out float calpha) {\n	vec4 color = colors[0];\n	#ifdef g_uid30_IS_VECTOR\n		#ifdef g_uid30_LINEAR\n			#ifdef g_uid30_WORLDSPACE\n			float depth = vectorLinearWorldSpaceDepth(direction, origin, near, far);\n			#else\n			float depth = vectorLinearObjectSpaceDepth(direction, origin, near, far);\n			#endif\n		#else\n			#ifdef g_uid30_WORLDSPACE\n				float depth = vectorSphericalWorldSpaceDepth(origin, near, far);\n			#else\n				float depth = vectorSphericalObjectSpaceDepth(origin, near, far);\n			#endif\n		#endif\n	#else\n		float dist = length(vWPosition - cameraPosition);\n		float depth = ( dist - near ) / ( far - near );\n	#endif\n\n\n	float p;\n	#ifdef g_uid30_SMOOTH\n	for ( int i = 1; i < g_uid30_MAX_COLORS; i++ ) {\n			p = clamp( ( depth - steps[i-1] ) / ( steps[i] - steps[i-1] ), 0.0, 1.0 );\n			color = mix(color, colors[i], smoothstep(0.0, 1.0, p));\n		}\n	#else\n	for ( int i = 1; i < g_uid30_MAX_COLORS; i++ ) {\n		p = clamp(( depth - steps[i - 1] ) / ( steps[i] - steps[i - 1] ), 0.0, 1.0);\n		color = mix(color, colors[i], p);\n		}\n	#endif\n\n	float lalpha = alpha * color.a * mask;\n	calpha = mix(lalpha / clamp(lalpha + accumAlpha, 0.00001, 1.0), lalpha, float(isMask));\n	accumAlpha += (1.0 - accumAlpha) * lalpha * (1.0 - float(isMask));\n	\n	return color.rgb;\n}\nvec3 getIBLVolumeRefraction( vec3 n, vec3 v, float roughness, vec3 position, mat4 modelMatrix, mat4 viewMatrix, mat4 projMatrix, float ior, float thickness, vec2 transmissionSamplerSize, sampler2D transmissionSamplerMap, sampler2D transmissionDepthMap, vec2 aspectRatio ) {\n	vec3 transmissionRay = getVolumeTransmissionRay( n, v, thickness, ior, modelMatrix );\n	vec3 refractedRayExit = position + transmissionRay;\n\n	// Project refracted vector on the framebuffer, while mapping to normalized device coordinates.\n	vec4 ndcPos = projMatrix * viewMatrix *  vec4( refractedRayExit, 1.0 );\n	vec2 refractionCoords = ndcPos.xy / ndcPos.w;\n	refractionCoords += 1.0;\n	refractionCoords /= 2.0;\n\n	vec4 ndcPosUnrefracted = projMatrix * viewMatrix * vec4(position, 1.0 );\n	vec2 unrefractedCoords = ndcPosUnrefracted.xy / ndcPosUnrefracted.w;\n	unrefractedCoords += 1.0;\n	unrefractedCoords /= 2.0;\n\n	// Sample framebuffer to get pixel the refracted ray hits.\n	return getTransmissionSample( refractionCoords, roughness, ior, transmissionSamplerSize, transmissionSamplerMap, transmissionDepthMap, unrefractedCoords, aspectRatio );\n}\nvec3 transmission(float thickness, float ior, float roughness, vec2 transmissionSamplerSize, sampler2D transmissionSamplerMap, sampler2D transmissionDepthMap, vec2 aspectRatio, vec3 normal, float mask, float alpha, out float calpha) {\n	vec3 v = vec3(0.);\n	if (isOrthographic) {\n		v = normalize( vec3( - viewMatrix[ 0 ][ 2 ], - viewMatrix[ 1 ][ 2 ], - viewMatrix[ 2 ][ 2 ] ) );\n	} else {\n		v = normalize(vWPosition - cameraPosition);\n	}\n\n	vec3 transmission = getIBLVolumeRefraction(normal, -v, roughness,  vWPosition, modelMatrix, viewMatrix, projectionMatrix, ior, thickness, transmissionSamplerSize, transmissionSamplerMap, transmissionDepthMap, aspectRatio );\n	\n	float lalpha = alpha * mask;\n	calpha =  lalpha / clamp( lalpha + accumAlpha, 0.00001, 1.0 );\n	accumAlpha += ( 1.0 - accumAlpha ) * alpha;\n\n	return transmission;\n}\nfloat voronoi(in vec3 x, in int style, in float smoothness, in float seed, in int quality) {\n	// Integer and fractional parts of this point\'s coordinates\n	ivec3 p = ivec3(floor(x));\n	vec3 f = fract(x);\n\n	// Different variables that we will use to construct noise:\n	//\n	// f1: distance to the closest feature point\n	// f2: distance to the second closest feature point\n	// e: distance to the closest edge (cell boundary)\n	//\n	// We also compute "smooth" versions of all of the above quantites, essentially\n	// replacing "hard" minimums with "smooth" minimums (described by IQ)\n	float f1_smooth = 8.0;\n	float f1 = 8.0;\n	float f2_smooth = 8.0;\n	float f2 = 8.0;\n	float e_smooth = 8.0;\n	float e = 8.0;\n\n	// Variables stored from closest cell\n	ivec3 mb;\n	vec3 mr; \n\n	int steps = quality;\n	\n	for (int x = -steps; x <= steps; x++) \n	for (int y = -steps; y <= steps; y++)\n	for (int z = -steps; z <= steps; z++)\n	{\n		ivec3 b = ivec3(x, y, z);\n		vec3 r = vec3(b) + hashwithoutsine33(vec3(p + b) + seed) - f;\n		float d = length(r);\n		\n		f1_smooth = smin(d, f1_smooth, smoothness);\n\n		// Store un-smoothed distances too \n		if (d < f1) \n		{\n			f2 = f1;\n			f1 = d;\n\n			mb = ivec3(x, y, z);\n			mr = r;\n		} \n		else if (d < f2) \n		{\n			f2 = d;\n		}\n	}	\n	\n	// Second pass for edge distance  \n	// skip for styles don\'t need\n	if (style != 0 &&  style != 5 && style != 7)\n	for (int x = -steps; x <= steps; x++) \n	for (int y = -steps; y <= steps; y++)\n	for (int z = -steps; z <= steps; z++)\n	{\n		// Start search at the cell that contains the closest point to "x" (found in 1st pass)\n		ivec3 b = mb + ivec3(x, y, z);\n		vec3 r = vec3(b) + hashwithoutsine33(vec3(p + b) + seed) - f;\n		float d1 = dot(0.5 * (mr + r), (r - mr)); 				// IQ normalizes "r - mr" but that breaks things for the smooth version?\n		float d2 = dot(0.5 * (mr + r), normalize(r - mr));\n\n		e_smooth = smin(d1, e_smooth, smoothness);\n\n		e = min(e, d2);\n\n		// Also compute a smooth version of F2 in this pass\n		{\n			ivec3 b = ivec3(x, y, z);\n			if (b != mb) \n			{\n				vec3 r = vec3(b) + hashwithoutsine33(vec3(p + b) + seed) - f;\n				float d = length(r);\n\n				f2_smooth = smin(d, f2_smooth, smoothness);\n			}\n		}\n	}\n\n	// Different visualization modes \n	if (style == 0) \n	{\n		return f1_smooth;\n	}\n	if (style == 1) \n	{\n		return f2_smooth;\n	}\n	if (style == 2) \n	{\n		return f2_smooth - f1_smooth;\n		\n		// "Pebbles" also cool\n		//return step(0.2, f2_smooth - f1_smooth);\n	}\n	if (style == 3) \n	{\n		// This one is really good for rock / stone effects\n		float a = f1; \n		float b = f2;\n		float k = 3.0;\n		float h = max(k - abs(a - b), 0.0) / k;\n		float final = min(a, b) - h * h * k * (1.0 / 4.0);\n		return final;\n	}\n	if (style == 4) \n	{\n		// Some random adjustments to make this style stand out more \n		return exp(5.0 * e_smooth);\n	}\n	if (style == 5) \n	{\n		return pow(f1_smooth, 3.0);\n	}\n	if (style == 6) \n	{				\n		const float eps = 0.0125;\n\n		// Thicker lines as the user increases the smoothness slider\n		float thickness = smoothness * 0.25 + eps;\n\n		// Blurrier lines as the user increases the smoothness slider\n		float blur = pow(smoothness, 3.0) * 0.25 + eps;\n\n		return smoothstep(\n			thickness - thickness * blur, \n			thickness + thickness * blur, \n			e\n		);\n	}\n	if (style == 7) \n	{\n		return hashwithoutsine13(vec3(p + mb) + seed);\n	}\n}\n\nvec3 simplexFastcustomNoise(float scale, vec3 size, float move, vec2 fA, vec2 fB, vec2 distortion, vec4 colorA, vec4 colorB, vec4 colorC, vec4 colorD, int voronoiStyle, float highCut, float lowCut, float smoothness, float seed, int quality, bool isMask, float mask, float alpha, out float calpha) {\n	// Prevent scale of zero \n	scale = max(abs(scale), 0.001);\n\n	vec3 st = vPosition / size;\n	st /= scale;\n\n	\n	vec3 q = vec3(simplexFast(st),\n				simplexFast(st + vec3(1.0)),\n				simplexFast(st + vec3(1.0)));\n	vec3 r = vec3(simplexFast(st + vec3(distortion, 1.0) * q + vec3(fA, 1.0) + move),\n				simplexFast(st + vec3(distortion, 1.0) * q + vec3(fB, 1.0) + move), \n				simplexFast(st * q));\n	float f = simplexFast(st + r);\n	vec4 color;\n	color = mix(colorA, colorB, clamp((f * f) * 4.0, 0.0, 1.0));\n	color = mix(color, colorC, clamp(length(q), 0.0, 1.0));\n	color = mix(color, colorD, clamp(length(r.x), 0.0, 1.0));\n\n\n	float lalpha = alpha * color.a * mask;\n	calpha = mix(lalpha / clamp(lalpha + accumAlpha, 0.00001, 1.0), lalpha, float(isMask));\n	accumAlpha += (1.0 - accumAlpha) * lalpha * (1.0 - float(isMask));\n\n	return clamp(color, 0.0, 1.0).rgb;\n}\n\nvoid main() {\n	float g_uid75_calpha;\n	#include <normal_fragment_begin>\n\n	vec3 finalNormal = vWNormal;\n	if(hasNormalMap){\n		vec3 normalMapColor = texture2D(normalMap, vUv).rgb;\n		vec3 normalMapNormal = normalMapColor * 2.0 - 1.0;\n		normalMapNormal.xy *= normalScale;\n		finalNormal = normalize(vWNormal + normalMapNormal);\n	}\n\n	vec3 outgoingLight = outgoingLight;\n	vec3 finalColor = spe_blend(outgoingLight, transmission(thickness, ior, roughness, transmissionSamplerSize, transmissionSamplerMap, transmissionDepthMap, aspectRatio,finalNormal, 1.0, mask, g_uid75_calpha), 1.0, 0);\n	gl_FragColor = vec4(finalColor, accumAlpha * alpha * 1.0 );\n	gl_FragColor.a *= opacity;\n	#include <fog_fragment>\n	#include <dithering_fragment>\n}\n',name:"GlassMorph",transparent:!0,opacity:1,depthTest:!0,depthWrite:!0,depthFunc:3,blending:1,blendSrc:204,blendDst:205,blendEquation:100,dithering:!0,fog:!0,toneMapped:!0})}}var h=t(1024);let g=e=>Math.PI/180*e,y=e=>new u.Pq0(e.x,e.y,e.z),_=e=>new u.O9p(e.x,e.y,e.z),w=e=>new h.eB(e.x,e.y,e.z),b=new u.Q1f("#c9ccd4");function z(){let e=(0,l.useRef)([]),n=(0,l.useRef)(null),t=(0,l.useRef)(null),a=(0,l.useRef)([]),i=(0,l.useRef)([]),{size:r}=(0,m.A)(),s=new u.G_z({color:new u.Q1f("silver"),emissive:b}),c=e=>{let{position:t={x:0,y:0,z:0},rotation:o={x:0,y:0,z:0}}=e,a=new u.bdM(20,20),i=new u.V9B({color:new u.Q1f("red"),side:u.$EB,transparent:!0,opacity:.5}),r=new u.eaF(a,i);r.position.copy(y(t)),r.rotation.copy(_(o));let s=new h.nB({mass:0,shape:new h.Zc,position:w(t),quaternion:new h.PT().setFromEuler(o.x,o.y,o.z)});return n.current&&n.current.addBody(s),r.visible=!1,{mesh:r,body:s}},d=()=>{let e=[{x:0,y:0,z:0},{x:0,y:0,z:8},{x:0,y:-4,z:0},{x:0,y:4,z:0}],n=[{x:0,y:0,z:0},{x:0,y:g(-180),z:0},{x:g(-90),y:0,z:0},{x:g(90),y:0,z:0}];for(let t=0;t<4;t++){let o=c({position:e[t],rotation:n[t]});a.current[50+t+1]=o,i.current[t]=o}};(0,l.useEffect)(()=>(n.current=new h.HK({gravity:new h.eB(0,-9.82,0)}),n.current.defaultContactMaterial.friction=.3,n.current.defaultContactMaterial.restitution=.7,d(),()=>{n.current&&n.current.bodies.forEach(e=>{var t;return null===(t=n.current)||void 0===t?void 0:t.removeBody(e)})}),[r]),(0,m.C)(o=>{if(!n.current||(n.current.step(1/60),e.current.forEach(e=>{let n=new u.Pq0().copy(e.body.position).normalize().multiplyScalar(-36);e.body.applyForce(n)}),a.current.forEach(e=>{let{mesh:n,body:t}=e;n.position.copy(t.position),n.quaternion.copy(t.quaternion)}),!t.current))return;let i=t.current,{pointer:r,viewport:s}=o,l=r.x*s.width/2,c=r.y*s.height/2,d=i.position.x+(l-i.position.x)*.1,v=i.position.y+(c-i.position.y)*.1,p=new h.eB(d,v,2.5);i.position.copy(p)});let v=t=>{let o=.5*Math.random()+.5,i=new u.Pq0(5*Math.random()-5,5*Math.random()-5,0),r=new u.Gu$(o,32,32),l=new u.eaF(r,s);l.position.copy(i);let c=new h.nB({mass:1,shape:new h.iy(o),position:new h.eB(i.x,i.y,i.z)});return n.current&&n.current.addBody(c),e.current[t]={mesh:l,body:c},49===t&&e.current.forEach(e=>{e.body.angularDamping=.2,e.body.linearDamping=.95}),a.current[t]={mesh:l,body:c},l};return(0,o.jsxs)(o.Fragment,{children:[[...Array(50).keys()].map(e=>{let n=v(e);return(0,o.jsx)("primitive",{object:n},e)}),i.current.map((e,n)=>(0,o.jsx)("primitive",{object:e.mesh},"plane-".concat(n))),(0,o.jsx)("primitive",{object:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:2,o=new u.Gu$(1,64,64),i=new u.eaF(o,s);i.scale.copy(new u.Pq0(e,e,e));let r=new h.nB({mass:1,shape:new h.iy(e),type:h.nB.KINEMATIC});return n.current&&n.current.addBody(r),i.visible=!1,t.current=r,a.current[50]={mesh:i,body:r},i}()})]})}var S=t(2557);let P=new u.Q1f("#6981b5"),M=()=>{let{gl:e,scene:n,camera:t,size:a}=(0,m.A)(),i=(e,n)=>e>=n?new u.I9Y(e/n,1):new u.I9Y(1,n/e);a.width,a.height,(0,l.useMemo)(()=>{let e=[];for(let n=0;n<10;n++)for(let t=0;t<10;t++){let o=2.01*n-9.044999999999998,a=2.01*t-9.044999999999998;e.push({position:[o,a,4]})}return e},[10,2.01]);let[r,s,c,d]=(0,l.useMemo)(()=>{let o=window.devicePixelRatio,r=new u.nWS(a.width*o/2,a.height*o/2,{generateMipmaps:!0,minFilter:u.NZq,magFilter:u.k6q,wrapS:u.ghU,wrapT:u.ghU,depthBuffer:!1}),s=new u.I9Y(a.width,a.height),l=new x({alpha:30,thickness:4,ior:1.19,roughness:4,outgoingLight:n.background instanceof u.Q1f?n.background:new u.Q1f(203,203,203),transmissionSamplerMap:r.texture,transmissionSamplerSize:s,aspectRatio:i(a.width,a.height)}),c=new u.V9B({map:r.texture}),d=new S.s0(e);d.addPass(new S.AH(n,t));let v=new S.Xe(n,t);d.addPass(v);let p={rangeThreshold:.5,rangeFalloff:.1,bias:.5},m=new S.w2(t,v.texture,{...p,color:P,samples:9,radius:30,intensity:30}),f=new S.w2(t,v.texture,{...p,color:P,samples:18,radius:5,intensity:30}),h=new S.Vu(t,m,f);return h.renderToScreen=!0,d.addPass(h),[d,r,c,l]},[e,a]);return(0,m.C)(()=>{r.render(),c.needsUpdate=!0,d.needsUpdate=!0},1),(0,l.useEffect)(()=>{r.setSize(a.width,a.height)},[a]),(0,o.jsx)(o.Fragment,{})},E=()=>{let e=(0,l.useRef)(null);return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)("ambientLight",{intensity:.75,color:"white"}),(0,o.jsx)("directionalLight",{position:[0,5,-5],color:"white",intensity:4}),(0,o.jsx)("spotLight",{position:[20,20,25],color:P,intensity:1}),(0,o.jsx)("group",{ref:e,position:[0,0,-3],children:(0,o.jsx)("mesh",{position:[0,0,0],children:(0,o.jsx)(z,{})})}),(0,o.jsx)(M,{})]})},D=e=>{let{className:n}=e;return(0,o.jsx)("div",{className:n,style:{position:"fixed",top:0,left:0,width:"100%",height:"100%",touchAction:"none"},children:(0,o.jsxs)(f.Hl,{orthographic:!0,camera:{zoom:100,position:[0,0,10]},dpr:[1,2],gl:{alpha:!0,outputColorSpace:u.Zr2},children:[(0,o.jsx)("color",{attach:"background",args:["#ffffff"]}),(0,o.jsx)(E,{})]})})};function L(){let e=(0,l.useCallback)(e=>{let n=document.documentElement,t=e.clientX,o=e.clientY;n.style.setProperty("--x","".concat(t,"px")),n.style.setProperty("--y","".concat(o,"px"))},[]);return(0,l.useEffect)(()=>(window.addEventListener("pointermove",e),window.addEventListener("pointerdown",e),e({clientX:window.innerWidth/2,clientY:window.innerHeight/2}),()=>{window.removeEventListener("pointermove",e),window.removeEventListener("pointerdown",e)}),[e]),(0,o.jsxs)("div",{className:i().heroSection,"data-hover-target":"heroSection",children:[(0,o.jsx)("div",{className:i().bg,children:(0,o.jsx)("div",{className:i().canvasMask,children:(0,o.jsx)(D,{})})}),(0,o.jsxs)("div",{className:i().content,children:[(0,o.jsx)("div",{className:i().logo,children:(0,o.jsx)(p,{})}),(0,o.jsxs)("div",{className:i().title,children:[(0,o.jsx)("div",{className:i().mainTitle,children:"Shapeshifiting Creativity"}),(0,o.jsxs)("div",{className:i().subTitle,children:["트렌디한 기술력, 독보적인 디자인에 창의성을 더해",(0,o.jsx)("br",{})," 다양한 형태의 디지털 콘텐를 만들어냅니다."]})]}),(0,o.jsx)(c,{})]})]})}},2946:e=>{e.exports={prism:"PrismEffect_prism__aGWZy",fadeIn:"PrismEffect_fadeIn__4K1Gf",anim:"PrismEffect_anim__sERsK"}},3718:e=>{e.exports={card:"DesktopPortfolio_card__IGdV7",content:"DesktopPortfolio_content__JkalR",timeInfo:"DesktopPortfolio_timeInfo__uhmf1",year:"DesktopPortfolio_year__7w8FH",duration:"DesktopPortfolio_duration__FSj36",title:"DesktopPortfolio_title__9YhJX",dimBg:"DesktopPortfolio_dimBg__jryBO",hoverContent:"DesktopPortfolio_hoverContent__zJIWh",text:"DesktopPortfolio_text__GlcCf"}},6493:e=>{e.exports={contents:"DesktopWorkContents_contents__9xVXH",mainTitleDescription:"DesktopWorkContents_mainTitleDescription__XmUJo",buttonPortfolioList:"DesktopWorkContents_buttonPortfolioList__GH4xy"}},7907:e=>{e.exports={wrapper:"ParallaxCard_wrapper__MXVFX",me:"ParallaxCard_me__QjbZk",glass:"ParallaxCard_glass__4FmB1",text:"ParallaxCard_text__tLZII"}},8334:e=>{e.exports={main:"page_main__GlU4n"}},9348:e=>{e.exports={card:"MobilePortfolio_card__Qzxex",content:"MobilePortfolio_content__bbbQc",timeInfo:"MobilePortfolio_timeInfo__YVSep",year:"MobilePortfolio_year__7oZCU",duration:"MobilePortfolio_duration__4u6AD",title:"MobilePortfolio_title__eWfR0",dimBg:"MobilePortfolio_dimBg__VMJBB",hoverContent:"MobilePortfolio_hoverContent__ufYLg",text:"MobilePortfolio_text__0eGBh"}},9672:(e,n,t)=>{"use strict";t.d(n,{WorkSection:()=>b});var o=t(5155),a=t(2115),i=t(6493),r=t.n(i),s=t(9938),l=t.n(s);let c=e=>{let{className:n}=e;return(0,o.jsxs)("div",{className:"".concat(l().mainTitleDescription," ").concat(n),children:[(0,o.jsxs)("div",{className:l().frame109,children:[(0,o.jsx)("div",{className:l().works,children:"Works"}),(0,o.jsx)("div",{"data-svg-wrapper":!0,className:l().iconArrow,children:(0,o.jsxs)("svg",{width:"41",height:"40",viewBox:"0 0 41 40",fill:"none",xmlns:"http://www.w3.org/2000/svg",children:[(0,o.jsx)("path",{d:"M40.5 20C40.5 31.0457 31.5457 40 20.5 40C9.4543 40 0.5 31.0457 0.5 20C0.5 8.9543 9.4543 0 20.5 0C31.5457 0 40.5 8.9543 40.5 20Z",fill:"#313131"}),(0,o.jsx)("path",{d:"M21.8333 13L28.5 20M28.5 20L21.8333 27M28.5 20L12.5 20",stroke:"white",strokeLinecap:"round",strokeLinejoin:"round"})]})})]}),(0,o.jsxs)("div",{className:l().description,children:["다양하고 뛰어난 기술력으로 요구 사항에 맞는 콘텐츠와 서비스를 제공하며",(0,o.jsx)("br",{}),"비주얼 퀄리티를 놓치지 않기 위해 더 많은 노력을 더합니다."]})]})};var d=t(3718),v=t.n(d),p=t(1639),m=t(5565);let f=e=>{let{index:n=0,category:t="분류",title:i="포트폴리오 제목",description:r="포트폴리오 설명이 이곳에 들어갑니다.",thumbnail:s="/images/works/protfolio.png"}=e,[l,c]=(0,a.useState)(!1);return(0,o.jsxs)(p.P.div,{"data-hover-target":"card",className:v().card,layout:!0,initial:{opacity:0,y:50},whileInView:{opacity:1,y:0},transition:{opacity:{duration:1,ease:"easeOut"}},viewport:{once:!0,amount:.1},onMouseEnter:()=>c(!0),onMouseLeave:()=>c(!1),children:[(0,o.jsx)(m.default,{fill:!0,src:s,alt:"",style:{objectFit:"cover",transform:l?"scale(1.1)":"scale(1.0)",transition:"all 0.3s ease-in-out"}}),(0,o.jsx)(p.P.div,{className:v().content,initial:{opacity:1},animate:{opacity:+!l},transition:{duration:.3}}),(0,o.jsx)(p.P.div,{className:v().dimBg,initial:{opacity:0},animate:{opacity:+!!l},transition:{duration:.3}}),(0,o.jsx)(p.P.div,{className:v().hoverContent,initial:{opacity:0,y:20},animate:{opacity:+!!l,y:20*!l},transition:{duration:.3},children:(0,o.jsxs)("div",{className:v().text,children:[(0,o.jsx)("h3",{children:t}),(0,o.jsx)("h2",{children:i}),(0,o.jsx)("p",{children:r})]})})]})},u=e=>{let{className:n}=e,t=[{id:"119:462"},{id:"119:465"},{id:"119:467"},{id:"119:469"}];return(0,o.jsxs)("div",{className:"".concat(r().contents," ").concat(n),children:[(0,o.jsx)(c,{className:r().mainTitleDescription}),(0,o.jsx)("div",{className:r().buttonPortfolioList,children:t.map((e,n)=>(0,o.jsx)(f,{index:n,title:"포트폴리오 제목",description:"포트폴리오 설명이 이곳에 들어갑니다."},e.id))}),(0,o.jsx)("div",{className:r().buttonPortfolioList,children:t.map((e,n)=>(0,o.jsx)(f,{index:n,title:"포트폴리오 제목",description:"포트폴리오 설명이 이곳에 들어갑니다."},e.id))})]})};var x=t(1143),h=t.n(x),g=t(9348),y=t.n(g);let _=e=>{let{index:n=0,category:t="분류",title:i="포트폴리오 제목",description:r="포트폴리오 설명이 이곳에 들어갑니다.",thumbnail:s="/images/works/protfolio.png"}=e,[l,c]=(0,a.useState)(!1);return(0,o.jsxs)(p.P.div,{"data-hover-target":"card",className:y().card,layout:!0,initial:{opacity:0,y:50},whileInView:{opacity:1,y:0},transition:{opacity:{duration:1,ease:"easeOut"}},viewport:{once:!0,amount:.1},onMouseEnter:()=>c(!0),onMouseLeave:()=>c(!1),children:[(0,o.jsx)(m.default,{fill:!0,src:s,alt:"",style:{objectFit:"cover",transform:l?"scale(1.1)":"scale(1.0)",transition:"all 0.3s ease-in-out"}}),(0,o.jsx)(p.P.div,{className:y().content,initial:{opacity:1},animate:{opacity:+!l},transition:{duration:.3}}),(0,o.jsx)(p.P.div,{className:y().dimBg,initial:{opacity:0},animate:{opacity:+!!l},transition:{duration:.3}}),(0,o.jsx)(p.P.div,{className:y().hoverContent,initial:{opacity:0,y:20},animate:{opacity:+!!l,y:20*!l},transition:{duration:.3},children:(0,o.jsxs)("div",{className:y().text,children:[(0,o.jsx)("h3",{children:t}),(0,o.jsx)("h2",{children:i}),(0,o.jsx)("p",{children:r})]})})]})},w=e=>{let{className:n}=e;return(0,o.jsxs)("div",{className:"".concat(h().contents," ").concat(n),children:[(0,o.jsx)(c,{className:h().mainTitleDescription}),(0,o.jsx)("div",{className:h().portfolioList,children:[{id:"1",category:"웹 개발",title:"모바일 웹 앱 프로젝트",description:"React와 Next.js를 활용한 반응형 웹 앱 개발"},{id:"2",category:"UI/UX 디자인",title:"모바일 앱 디자인",description:"사용자 경험을 고려한 모바일 앱 UI/UX 디자인"},{id:"3",category:"프론트엔드",title:"반응형 웹사이트",description:"모바일 퍼스트 접근 방식의 반응형 웹사이트 개발"},{id:"4",category:"백엔드",title:"API 서비스 개발",description:"Node.js와 Express를 활용한 RESTful API 개발"}].map((e,n)=>(0,o.jsx)(_,{index:n,category:e.category,title:e.title,description:e.description},e.id))})]})},b=()=>{let[e,n]=(0,a.useState)(!1);return(0,a.useEffect)(()=>{let e=()=>{n(window.innerWidth<=768)};return e(),window.addEventListener("resize",e),()=>{window.removeEventListener("resize",e)}},[]),(0,o.jsx)("section",{children:e?(0,o.jsx)(w,{}):(0,o.jsx)(u,{})})}},9938:e=>{e.exports={mainTitleDescription:"MainTitleDescription_mainTitleDescription__41iNd",frame109:"MainTitleDescription_frame109__NrkJq",works:"MainTitleDescription_works__n0Bv8",iconArrow:"MainTitleDescription_iconArrow__f1fwT",description:"MainTitleDescription_description__obVIE"}}},e=>{var n=n=>e(e.s=n);e.O(0,[901,367,831,664,413,547,639,565,521,441,587,358],()=>n(1562)),_N_E=e.O()}]);